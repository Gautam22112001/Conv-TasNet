{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speech-separation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPw+T/maA52G3auRuAZGnac"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4nzfoun37JMa"},"source":["# Speech Separation by Pretrained Models"]},{"cell_type":"code","metadata":{"id":"BQ7c_pW-3Gtj"},"source":["%%shell\n","git clone https://github.com/tky823/DNN-based_source_separation.git\n","\n","cd \"./DNN-based_source_separation/egs/tutorials/\"\n","\n","# To install torch & torchaudio\n","pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPAGmvZV2_yV"},"source":["%%shell\n","# Download speech dataset\n","for spk in aew axb bdl ; do\n","    wget \"http://festvox.org/cmu_arctic/packed/cmu_us_${spk}_arctic.tar.bz2\"\n","    tar -xjvf \"./cmu_us_${spk}_arctic.tar.bz2\" \n","done"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVrpBGYQ3Jsv"},"source":["import sys\n","sys.path.append(\"/content/DNN-based_source_separation/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cncPvFUB3Nd2"},"source":["import IPython.display as ipd\n","import torch\n","import torchaudio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"grI0SYYB3PzV"},"source":["from models.lstm_tasnet import LSTMTasNet\n","from models.conv_tasnet import ConvTasNet\n","from models.dprnn_tasnet import DPRNNTasNet\n","from models.dptnet import DPTNet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNSGY59z3Tok"},"source":["waveform_aew, sample_rate = torchaudio.load(\"/content/cmu_us_aew_arctic/wav/arctic_a0001.wav\")\n","waveform_axb, sample_rate = torchaudio.load(\"/content/cmu_us_axb_arctic/wav/arctic_a0002.wav\")\n","waveform_bdl, sample_rate = torchaudio.load(\"/content/cmu_us_bdl_arctic/wav/arctic_a0003.wav\")\n","SAMPLE_RATE_WSJ0 = 8000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxUsAPHu5Kl2"},"source":["resampler = torchaudio.transforms.Resample(sample_rate, SAMPLE_RATE_WSJ0)\n","waveform_aew = resampler(waveform_aew)\n","waveform_axb = resampler(waveform_axb)\n","waveform_bdl = resampler(waveform_bdl)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SS_eYo6b4A6e"},"source":["T_min = min(waveform_aew.size(-1), waveform_axb.size(-1), waveform_bdl.size(-1))\n","waveform_aew, waveform_axb, waveform_bdl = waveform_aew[:, :T_min], waveform_axb[:, :T_min], waveform_bdl[:, :T_min]\n","display(ipd.Audio(waveform_aew, rate=SAMPLE_RATE_WSJ0))\n","display(ipd.Audio(waveform_axb, rate=SAMPLE_RATE_WSJ0))\n","display(ipd.Audio(waveform_bdl, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28_wMyLv75ti"},"source":["## 2 speakers"]},{"cell_type":"code","metadata":{"id":"zizEZrvp5ACM"},"source":["n_sources = 2\n","mixture = waveform_aew + waveform_axb\n","display(ipd.Audio(mixture, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvRRn3-r4Eyb"},"source":["model = LSTMTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqSe2Evd6MRf"},"source":["model = ConvTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDrHvPXy6pnJ"},"source":["model = DPRNNTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u82Qi5ML6wwr"},"source":["model = DPTNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3ixQJPb8F2I"},"source":["## 3 speakers"]},{"cell_type":"code","metadata":{"id":"Ri9q1DEZ699U"},"source":["n_sources = 3\n","mixture = waveform_aew + waveform_axb + waveform_bdl\n","display(ipd.Audio(mixture, rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTWK_e4P8KKa"},"source":["model = ConvTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8GXERi08SEA"},"source":["model = DPRNNTasNet.build_from_pretrained(task=\"wsj0-mix\", sample_rate=SAMPLE_RATE_WSJ0, n_sources=n_sources)\n","\n","input = mixture.unsqueeze(dim=0)\n","\n","model.eval()\n","with torch.no_grad():\n","    output = model(input)\n","\n","output = output.squeeze(dim=0)\n","estimated = torch.split(output, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(estimated[idx], rate=SAMPLE_RATE_WSJ0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDy6cBP38iRm"},"source":[""],"execution_count":null,"outputs":[]}]}