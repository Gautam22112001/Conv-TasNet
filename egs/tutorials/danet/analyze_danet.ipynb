{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oJGuBqcr8t9E"},"outputs":[],"source":["%%shell\n","git clone https://github.com/tky823/DNN-based_source_separation.git\n","\n","cd \"./DNN-based_source_separation/egs/tutorials\"\n","\n","pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znqDA0JR3YOh"},"outputs":[],"source":["%%shell\n","# Download dataset\n","librispeech_root=\"/content/LibriSpeech\"\n","sample_rate=16000\n","\n","mkdir -p \"${librispeech_root}/test-clean\"\n","wget \"http://www.openslr.org/resources/12/test-clean.tar.gz\" -P \"/tmp\"\n","tar -xf \"/tmp/test-clean.tar.gz\" -C \"/tmp/\"\n","rm \"/tmp/test-clean.tar.gz\"\n","mv \"/tmp/LibriSpeech/test-clean/\"* \"${librispeech_root}/test-clean/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1SMiqdY8znS"},"outputs":[],"source":["import os\n","import sys\n","import random\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ii14lXvy9Jhv"},"outputs":[],"source":["sys.path.append(\"DNN-based_source_separation/src\")\n","random.seed(111)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rHmQculZ81Ca"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import IPython.display as ipd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cB9x9Oy82Yp"},"outputs":[],"source":["plt.rcParams['font.size'] = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY8GxVBF83dI"},"outputs":[],"source":["import torch\n","import torchaudio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_cOkMQj84f3"},"outputs":[],"source":["from utils.audio import build_window\n","from algorithm.frequency_mask import compute_ideal_binary_mask\n","from transforms.pca import PCA\n","from models.danet import DANet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAcpJ7_k86RR"},"outputs":[],"source":["COLORS = [\"red\", \"blue\"]\n","SAMPLE_RATE_LIBRISPEECH = 16000\n","\n","n_sources = 2\n","threshold = 40"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class WaveDataset:\n","    def __init__(self, librispeech_root, json_path=None):\n","        self.librispeech_root = librispeech_root\n","\n","        with open(json_path) as f:\n","            self.json_data = json.load(f)\n","\n","    def __getitem__(self, idx):\n","        data = self.json_data[idx]['sources']\n","    \n","        waveform_src = []\n","        \n","        for src_idx in range(n_sources):\n","            audio_path = os.path.join(self.librispeech_root, data['source-{}'.format(src_idx)]['path'])\n","            start = data['source-{}'.format(src_idx)]['start']\n","            end = data['source-{}'.format(src_idx)]['end']\n","            num_frames = end - start\n","            waveform, _ = torchaudio.load(audio_path, offset=start, num_frames=num_frames)\n","            waveform_src.append(waveform)\n","        \n","        waveform_src = torch.cat(waveform_src, dim=0)\n","        waveform_mix = torch.sum(waveform_src, dim=0, keepdim=True)\n","\n","        return waveform_mix, waveform_src\n","    \n","    def __len__(self):\n","        return len(self.json_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqWWXvS287fA"},"outputs":[],"source":["def create_sample_waveforms(n_sources=2):\n","    librispeech_root = \"/content/LibriSpeech\"\n","\n","    json_path = \"/content/DNN-based_source_separation/dataset/LibriSpeech/test-clean/test-{}mix.json\".format(n_sources)\n","    with open(json_path) as f:\n","        json_data = json.load(f)\n","    \n","    data_idx = 3\n","    data = json_data[data_idx]['sources']\n","    \n","    waveform_src = []\n","    \n","    for src_idx in range(n_sources):\n","        audio_path = os.path.join(librispeech_root, data['source-{}'.format(src_idx)]['path'])\n","        start = data['source-{}'.format(src_idx)]['start']\n","        end = data['source-{}'.format(src_idx)]['end']\n","        num_frames = end - start\n","        waveform, _ = torchaudio.load(audio_path, offset=start, num_frames=num_frames)\n","        waveform_src.append(waveform)\n","    \n","    waveform_src = torch.cat(waveform_src, dim=0)\n","    waveform_mix = torch.sum(waveform_src, dim=0, keepdim=True)\n","\n","    return waveform_mix, waveform_src"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIDTb4VJ89kw"},"outputs":[],"source":["def load_model(sample_rate=SAMPLE_RATE_LIBRISPEECH, n_sources=2):\n","    model = DANet.build_from_pretrained(task=\"librispeech\", sample_rate=sample_rate, n_sources=n_sources)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2coo2HrH9IOZ"},"outputs":[],"source":["def compute_threshold(amplitude, threshold=40, eps=1e-12):\n","    log_amplitude = 20 * torch.log10(amplitude + eps)\n","    max_log_amplitude = torch.max(log_amplitude)\n","    threshold = 10**((max_log_amplitude - threshold) / 20)\n","    threshold_weight = torch.where(amplitude > threshold, torch.ones_like(amplitude), torch.zeros_like(amplitude))\n","\n","    return threshold_weight"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def estimate(spectrogram_mix):\n","    amplitude_mix, phase_mix = torch.abs(spectrogram_mix), torch.angle(spectrogram_mix)\n","\n","    amplitude_mix = amplitude_mix.unsqueeze(dim=0)\n","    threshold_weight = compute_threshold(amplitude_mix)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        amplitude_est, latent, attractor = model.extract_latent(amplitude_mix, threshold_weight=threshold_weight, n_sources=n_sources)\n","\n","    threshold_weight = threshold_weight.squeeze(dim=0)\n","    attractor = attractor.squeeze(dim=0)\n","    latent = latent.squeeze(dim=0)\n","    amplitude_est = amplitude_est.squeeze(dim=0)\n","    spectrogram_est = amplitude_est * torch.exp(1j * phase_mix)\n","\n","    return spectrogram_est, latent, attractor, threshold_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"loINg6ie9C4x"},"outputs":[],"source":["librispeech_root = \"/content/LibriSpeech\"\n","json_path = \"/content/DNN-based_source_separation/dataset/LibriSpeech/test-clean/test-{}mix.json\".format(n_sources)\n","dataset = WaveDataset(librispeech_root, json_path=json_path)\n","# waveform_mix, waveform_src = create_sample_waveforms()\n","waveform_mix, waveform_src = dataset[0]\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(waveform_src[idx], rate=SAMPLE_RATE_LIBRISPEECH))\n","\n","display(ipd.Audio(waveform_mix, rate=SAMPLE_RATE_LIBRISPEECH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xL3gq9j8_JC"},"outputs":[],"source":["model = load_model(sample_rate=SAMPLE_RATE_LIBRISPEECH, n_sources=n_sources)\n","n_fft, hop_length = model.n_fft, model.hop_length\n","window_fn = model.window_fn\n","window = build_window(n_fft, window_fn=window_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G4vNqHB9GJf"},"outputs":[],"source":["spectrogram_mix = torch.stft(waveform_mix, n_fft=n_fft, hop_length=hop_length, window=window, onesided=True, return_complex=True)\n","spectrogram_src = torch.stft(waveform_src, n_fft=n_fft, hop_length=hop_length, window=window, onesided=True, return_complex=True)\n","\n","# Compute ideal binary mask for plotting\n","mask = compute_ideal_binary_mask(spectrogram_src, source_dim=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spectrogram_est, latent, attractor, threshold_weight = estimate(spectrogram_mix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc1deXwH9LY5"},"outputs":[],"source":["waveform_est = torch.istft(spectrogram_est, n_fft=n_fft, hop_length=hop_length, window=window, onesided=True, length=waveform_mix.size(-1), return_complex=False)\n","waveform_est = torch.split(waveform_est, [1]*n_sources, dim=0)\n","\n","for idx in range(n_sources):\n","    display(ipd.Audio(waveform_est[idx].detach(), rate=SAMPLE_RATE_LIBRISPEECH))"]},{"cell_type":"markdown","metadata":{"id":"fIgLy87t9Pls"},"source":["## Plot principal components"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOBwQrgB9X1I"},"outputs":[],"source":["def plot_latent_2d(latent, attractor, mask, alpha=0.1, lims=None):\n","    n_sources = mask.size(0)\n","    plt.figure(figsize=(12, 8))\n","\n","    for idx in range(n_sources):\n","        color = COLORS[idx]\n","        indices, = torch.nonzero(mask[idx].flatten(), as_tuple=True)\n","        x, y = torch.unbind(latent[indices], dim=1)[:2]\n","        plt.scatter(x, y, color=color, alpha=alpha)\n","    \n","    for idx in range(n_sources):\n","        x, y = torch.unbind(attractor[idx], dim=1)[:2]\n","        plt.scatter(x, y, color=\"black\", marker=\"^\", s=300, linewidths=3, edgecolors=\"white\")\n","\n","    if lims is not None:\n","        plt.xlim(lims)\n","        plt.ylim(lims)\n","\n","    plt.xlabel(\"PCA1\")\n","    plt.ylabel(\"PCA2\")\n","\n","    plt.show()\n","    plt.close()\n","\n","def plot_latent_3d(latent, attractor, mask, alpha=0.1, lims=None):\n","    n_sources = mask.size(0)\n","\n","    fig = plt.figure(figsize=(12, 8))\n","    ax = fig.add_subplot(111, projection='3d')\n","\n","    for idx in range(n_sources):\n","        color = COLORS[idx]\n","        indices, = torch.nonzero(mask[idx].flatten(), as_tuple=True)\n","        x, y, zs = torch.unbind(latent[indices], dim=1)[:3]\n","        ax.scatter(x, y, zs=zs, color=color, alpha=alpha)\n","    \n","    for idx in range(n_sources):\n","        x, y, zs = torch.unbind(attractor[idx], dim=1)[:3]\n","        ax.scatter(x, y, zs=zs, color=\"black\", marker=\"^\", s=300, linewidths=3, edgecolors=\"white\")\n","\n","    if lims is not None:\n","        ax.set_xlim(lims)\n","        ax.set_ylim(lims)\n","        ax.set_zlim(lims)\n","\n","    ax.set_xlabel(\"PCA1\")\n","    ax.set_ylabel(\"PCA2\")\n","    ax.set_zlabel(\"PCA3\")\n","\n","    plt.show()\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quGP5oMw9VHJ"},"outputs":[],"source":["latent = latent.view(-1, latent.size(-1))\n","salient_indices, = torch.nonzero(threshold_weight.flatten(), as_tuple=True)\n","latent_salient = latent[salient_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0v9frZ79M-z"},"outputs":[],"source":["# Applies PCA\n","pca = PCA()\n","\n","pca.train()\n","_ = pca(latent_salient)\n","\n","pca.eval()\n","latent_projected = pca(latent)\n","attractor_projected = pca(attractor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4a14Ok19V3B"},"outputs":[],"source":["plot_latent_2d(latent_projected, attractor_projected, mask * threshold_weight, lims=(-5, 5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arPGBYmU9aDb"},"outputs":[],"source":["plot_latent_3d(latent_projected, attractor_projected, mask * threshold_weight, lims=(-5, 5))"]},{"cell_type":"markdown","metadata":{},"source":["## Extract All Test Attractor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_f9_crQ9a3b"},"outputs":[],"source":["attractors = []\n","\n","for waveform_mix, waveform_src in dataset:\n","    spectrogram_mix = torch.stft(waveform_mix, n_fft=n_fft, hop_length=hop_length, window=window, onesided=True, return_complex=True)\n","\n","    _, _, attractor, _ = estimate(spectrogram_mix)\n","\n","    attractors.append(attractor)\n","\n","attractors = torch.stack(dim=0) # (len(dataset), embed_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_attractors_2d(attractors, alpha=0.1, lims=None):\n","    plt.figure(figsize=(12, 8))\n","\n","    x, y = torch.unbind(attractors, dim=1)[:2]\n","    plt.scatter(x, y, color=\"blue\", alpha=alpha)\n","\n","    if lims is not None:\n","        plt.xlim(lims)\n","        plt.ylim(lims)\n","\n","    plt.xlabel(\"PCA1\")\n","    plt.ylabel(\"PCA2\")\n","\n","    plt.show()\n","    plt.close()\n","\n","def plot_attractors_3d(attractors, alpha=0.1, lims=None):\n","    fig = plt.figure(figsize=(12, 8))\n","    ax = fig.add_subplot(111, projection='3d')\n","    \n","    x, y, zs = torch.unbind(attractors, dim=1)[:3]\n","    ax.scatter(x, y, zs=zs, color=\"blue\", alpha=alpha)\n","\n","    if lims is not None:\n","        ax.set_xlim(lims)\n","        ax.set_ylim(lims)\n","        ax.set_zlim(lims)\n","\n","    ax.set_xlabel(\"PCA1\")\n","    ax.set_ylabel(\"PCA2\")\n","    ax.set_zlabel(\"PCA3\")\n","\n","    plt.show()\n","    plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Applies PCA\n","pca = PCA()\n","\n","pca.train()\n","attractors_projected = pca(attractors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_attractors_2d(attractors_projected)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_attractors_3d(attractors_projected)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMgJp2tosHDr8gwNFitVGmH","collapsed_sections":[],"name":"analyze_danet.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
